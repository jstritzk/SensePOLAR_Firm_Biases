{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8ce7a5-3397-4ce2-a08c-175c64de09b3",
   "metadata": {},
   "source": [
    "# 01 Preparing Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14fa905-267f-46c9-b685-2fd2cf7898b0",
   "metadata": {},
   "source": [
    "The following notebook was used to clean, enrich and process the stereotype content dictionaries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f02cc38",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda79c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "import json\n",
    "import pickle\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df44f5dd",
   "metadata": {},
   "source": [
    "## 1. Process Seed Word Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcffa0",
   "metadata": {},
   "source": [
    "Processing the seed word list from: \n",
    "\n",
    "- *Nicolas, G., Bai, X., & Fiske, S. T. (2021). Comprehensive stereotype content dictionaries using a semi‐automated method. In European Journal of Social Psychology (Vol. 51, Issue 1, pp. 178–196). Wiley. https://doi.org/10.1002/ejsp.2724* \n",
    "\n",
    "which is included in the file *finalwordlist R 050418.csv* in the online supplement found under https://osf.io/yx45f/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bd0ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Politics Dictionary. \n",
    "final_dimensions_manual = pd.read_csv(\"dimensions_matched_manual.csv\", sep = \";\", index_col = 0)\n",
    "final_dimensions_manual = final_dimensions_manual[final_dimensions_manual.Dictionary != \"Politics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae3426a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term1</th>\n",
       "      <th>Synset1</th>\n",
       "      <th>Definition1</th>\n",
       "      <th>Example1</th>\n",
       "      <th>Synset2</th>\n",
       "      <th>Term2</th>\n",
       "      <th>Definition2</th>\n",
       "      <th>Example2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dictionary</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ability</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agency</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morality</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sociability</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Term1  Synset1  Definition1  Example1  Synset2  Term2  \\\n",
       "Dictionary                                                           \n",
       "Ability         24       24           24        24       24     24   \n",
       "Agency          20       20           20        20       20     20   \n",
       "Morality        26       26           26        26       26     26   \n",
       "Sociability     25       25           25        25       25     25   \n",
       "Status           8        8            8         8        8      8   \n",
       "\n",
       "             Definition2  Example2  \n",
       "Dictionary                          \n",
       "Ability               24        24  \n",
       "Agency                20        20  \n",
       "Morality              26        26  \n",
       "Sociability           25        25  \n",
       "Status                 8         8  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dimensions_manual.groupby(\"Dictionary\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e3a0655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read seed word list. \n",
    "seed_words = pd.read_csv(\"finalwordlist R 050418.csv\")\n",
    "seed_words = seed_words[seed_words[\"PoS\"] == \"ADJECTIVE\"]\n",
    "\n",
    "# Drop religion. \n",
    "seed_words = seed_words[seed_words[\"Dictionary\"] != \"Religion\"]\n",
    "\n",
    "\n",
    "# Add relevant WordNet information. \n",
    "def get_synset(row):\n",
    "    return wn.synsets(row[\"term\"], pos = wn.ADJ)[row[\"sense\"]-1].name()\n",
    "\n",
    "def get_definition(row):\n",
    "    return wn.synsets(row[\"term\"], pos = wn.ADJ)[row[\"sense\"]-1].definition()\n",
    "\n",
    "def get_example(row):\n",
    "    try: \n",
    "        return wn.synsets(row[\"term\"], pos = wn.ADJ)[row[\"sense\"]-1].examples()[0]\n",
    "    except:\n",
    "        pass\n",
    "      \n",
    "def get_antonyms(row):\n",
    "    antonyms = []\n",
    "    for lemma in wn.synsets(row[\"term\"], pos = wn.ADJ)[row[\"sense\"]-1].lemmas():\n",
    "        try: \n",
    "            for antonym in lemma.antonyms(): \n",
    "                antonyms.append(antonym.synset().name())\n",
    "        except: \n",
    "            pass\n",
    "    try: \n",
    "        return antonyms[0]\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "# Applying functions. \n",
    "seed_words[\"Synset\"] = seed_words.apply(lambda row: get_synset(row), axis=1)\n",
    "seed_words[\"Definition\"] = seed_words.apply(lambda row: get_definition(row), axis=1)\n",
    "seed_words[\"Examples\"] = seed_words.apply(lambda row: get_example(row), axis=1)\n",
    "seed_words[\"Antonyms\"] = seed_words.apply(lambda row: get_antonyms(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04590982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding sample sentences from Oxford Dictionaries for cases where there is no sample sentence on WordNet. \n",
    "\n",
    "app_id = \"27817df8\"\n",
    "app_key = \"b06cc3abf9e998663379f9e42d23a81e\"\n",
    "language = \"en-gb\"\n",
    "\n",
    "def get_examples_oxford(row):\n",
    "    \n",
    "    if row[\"Examples\"] is None:\n",
    "        try: \n",
    "            word_id = row[\"term\"]\n",
    "            url = \"https://od-api.oxforddictionaries.com:443/api/v2/entries/\" + language + \"/\" + word_id.lower()\n",
    "            result = requests.get(url, headers={\"app_id\": app_id, \"app_key\": app_key}) \n",
    "            result = json.loads(result.text)\n",
    "            result = result[\"results\"][0][\"lexicalEntries\"][0][\"entries\"][0][\"senses\"][0][\"examples\"][0][\"text\"]\n",
    "\n",
    "            return result \n",
    "\n",
    "        except: \n",
    "            pass\n",
    "        \n",
    "    else: \n",
    "        return row[\"Examples\"]\n",
    "    \n",
    "seed_words[\"Examples\"] = seed_words.apply(lambda row: get_examples_oxford(row), axis = 1)\n",
    "\n",
    "# Export to CSV to circumvent API limits. \n",
    "seed_words.to_csv(\"seed_words_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8eef18ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "seed_words = pd.read_csv(\"seed_words_raw.csv\", index_col = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc70c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sample_sentence(row):\n",
    "    \n",
    "    try: \n",
    "\n",
    "        if row[\"term\"] in row[\"Examples\"].split(\" \"): \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    except: \n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5c7ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_words[\"Sentence_Check\"] = seed_words.apply(lambda row: check_sample_sentence(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "870de645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV to circumvent API limits. \n",
    "seed_words.to_csv(\"seed_words_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bb563d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_words_manual = pd.read_csv(\"seed_words_manual_final.csv\", sep = \";\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d3cf1d",
   "metadata": {},
   "source": [
    "## 2. Match Antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "543c8fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_match_antonyms(df):\n",
    "    \n",
    "    # Split dictionary into high and low and remove dimensions with missing matches. \n",
    "    dict_high = df[(df[\"Dir\"] == \"high\") & (df[\"Antonyms\"].notnull())]\n",
    "    dict_low = df[(df[\"Dir\"] == \"low\") & (df[\"Antonyms\"].notnull())]\n",
    "    \n",
    "    # Clean and rename columns. \n",
    "    dict_high = dict_high[[\"Dictionary\", \"term\", \"Synset\", \"Definition\", \"Examples\", \"Antonyms\"]]\n",
    "    dict_high = dict_high.rename(columns={\"term\":\"Term1\", \"Synset\": 'Synset1', \"Definition\": \"Definition1\", \n",
    "                                          \"Examples\":\"Example1\", \"Antonyms\": \"Synset2\"})\n",
    "    \n",
    "    dict_low = dict_low[[\"term\", \"Synset\", \"Definition\", \"Examples\"]]\n",
    "    dict_low = dict_low.rename(columns={\"term\":\"Term2\", \"Synset\": 'Synset2', \"Definition\": \"Definition2\", \n",
    "                                       \"Examples\": \"Example2\"})\n",
    "    \n",
    "    # Merge both dictionaries. \n",
    "    dict_merged = pd.merge(dict_high, dict_low, on=[\"Synset2\"])\n",
    "    dict_merged = dict_merged.dropna().reset_index(drop = True)\n",
    "    dict_merged.drop_duplicates(inplace = True)\n",
    "    dict_merged.drop_duplicates(subset = [\"Synset1\"], inplace = True)\n",
    "\n",
    "    return dict_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9f363b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matched = clean_and_match_antonyms(seed_words_manual)\n",
    "final_dimensions = all_matched.reset_index(drop = True)\n",
    "final_dimensions.to_csv(\"final_dimensions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b87fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read after conducting manual steps described in methods. \n",
    "final_dimensions_manual = pd.read_csv(\"dimensions_matched_manual.csv\", sep = \";\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16bc3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Politics dictionary. \n",
    "final_dimensions_manual = final_dimensions_manual[final_dimensions_manual.Dictionary != \"Politics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "922d41c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Dimensions Sociability: 21 \n",
      "\n",
      "# of Dimensions Ability: 19 \n",
      "\n",
      "# of Dimensions Status: 7 \n",
      "\n",
      "# of Dimensions Agency: 18 \n",
      "\n",
      "# of Dimensions Morality: 24 \n",
      "\n",
      "# of Dimensions Politics: 0\n",
      "______________________________________\n",
      "\n",
      "Total # of Dimensions: 89\n"
     ]
    }
   ],
   "source": [
    "# Checking length of individual dictionaries. \n",
    "\n",
    "print(f\"\"\"# of Dimensions Sociability: {len(final_dimensions_manual[final_dimensions_manual[\"Dictionary\"] == \"Sociability\"])} \\n\n",
    "# of Dimensions Ability: {len(final_dimensions_manual[final_dimensions_manual[\"Dictionary\"] == \"Ability\"])} \\n\n",
    "# of Dimensions Status: {len(final_dimensions_manual[final_dimensions_manual[\"Dictionary\"] == \"Status\"])} \\n\n",
    "# of Dimensions Agency: {len(final_dimensions_manual[final_dimensions_manual[\"Dictionary\"] == \"Agency\"])} \\n\n",
    "# of Dimensions Morality: {len(final_dimensions_manual[final_dimensions_manual[\"Dictionary\"] == \"Morality\"])} \\n\n",
    "# of Dimensions Politics: {len(final_dimensions_manual[final_dimensions_manual[\"Dictionary\"] == \"Politics\"])}\n",
    "______________________________________\\n\n",
    "Total # of Dimensions: {len(final_dimensions_manual)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656ea6e5",
   "metadata": {},
   "source": [
    "## 3. Create Files compatible with SensePOLAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f1d181",
   "metadata": {},
   "source": [
    "To be compatible with the SensePolar framework, seed word lists are converted into different text and pkl files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c352260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_antonym_text_files(df):\n",
    "\n",
    "    example_sentences_readable = {}\n",
    "    get_lookup_anto_example_dict = []\n",
    "    get_lookup_synset_definition = []\n",
    "    get_lookup_synset_dict = []\n",
    "    \n",
    "    for entry in tqdm(df.index):\n",
    "        \n",
    "        # Create antonym_wordnet_example_sentences_readable_extended.txt\n",
    "        antonym_pair = str([str(df.at[entry, \"Synset2\"]), str(df.at[entry, \"Synset1\"])])\n",
    "        \n",
    "        term1 = df.at[entry, \"Term2\"]\n",
    "        term2 = df.at[entry, \"Term1\"]        \n",
    "        example1 = df.at[entry, \"Example2\"]\n",
    "        example2 = df.at[entry, \"Example1\"]\n",
    "        \n",
    "        sub_dict = {term1:[example1], term2:[example2]}\n",
    "        \n",
    "        example_sentences_readable[antonym_pair] = sub_dict\n",
    "    \n",
    "        # Create get_lookup_anto_example_dict. \n",
    "        get_lookup_anto_example_dict.append([[term1, [example1]], [term2, [example2]]])\n",
    "        \n",
    "        # Create get_lookup_synset_definition. \n",
    "        definition1 = df.at[entry, \"Definition2\"]\n",
    "        definition2 = df.at[entry, \"Definition1\"]\n",
    "        get_lookup_synset_definition.append([definition1, definition2])\n",
    "        \n",
    "        # Create get_lookup_synset_dict. \n",
    "        get_lookup_synset_dict.append(antonym_pair)\n",
    "\n",
    "    # Create text files. \n",
    "    with open('antonyms/antonym_wordnet_example_sentences_readable_extended.txt', 'w') as file:\n",
    "        file.write(json.dumps(example_sentences_readable, indent=4))\n",
    "    with open('antonyms/lookup_anto_example_dict.txt', 'w') as file:\n",
    "        file.write(json.dumps(get_lookup_anto_example_dict, indent=4))\n",
    "    with open('antonyms/lookup_synset_definition.txt', 'w') as file:\n",
    "        file.write(json.dumps(get_lookup_synset_definition, indent=4))        \n",
    "    with open('antonyms/lookup_synset_dict.txt', 'w') as file:\n",
    "        file.write(json.dumps(get_lookup_synset_dict, indent=4))\n",
    "        \n",
    "    # Create pkl files.    \n",
    "    with open('antonyms/lookup_anto_example_dict.pkl', 'wb') as file:\n",
    "        pickle.dump(get_lookup_anto_example_dict, file)\n",
    "    with open('antonyms/lookup_synset_definition.pkl', 'wb') as file:\n",
    "        pickle.dump(get_lookup_synset_definition, file)\n",
    "    with open('antonyms/lookup_synset_dict.pkl', 'wb') as file:\n",
    "        pickle.dump(get_lookup_synset_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27225166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8797883d7e4743de85f790775b3bf9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_antonym_text_files(final_dimensions_manual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
